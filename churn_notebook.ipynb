{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Customer Churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the environment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements_py3.8_local.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import plot_roc_curve, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['QT_QPA_PLATFORM']='offscreen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"./data/bank_data.csv\", index_col = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(f'Shape of data: {df.shape}')\n",
    "print(f'Columns of the data:')\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Null values count per column:')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Stats for quantitative columns:')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# categorical variables\n",
    "cat_columns = [\n",
    "    'Attrition_Flag',\n",
    "    'Gender',\n",
    "    'Education_Level',\n",
    "    'Marital_Status',\n",
    "    'Income_Category',\n",
    "    'Card_Category'\n",
    "]\n",
    "\n",
    "# quantitative variables\n",
    "quant_columns = [\n",
    "    'Customer_Age',\n",
    "    'Dependent_count', \n",
    "    'Months_on_book',\n",
    "    'Total_Relationship_Count', \n",
    "    'Months_Inactive_12_mon',\n",
    "    'Contacts_Count_12_mon', \n",
    "    'Credit_Limit', \n",
    "    'Total_Revolving_Bal',\n",
    "    'Avg_Open_To_Buy', \n",
    "    'Total_Amt_Chng_Q4_Q1', \n",
    "    'Total_Trans_Amt',\n",
    "    'Total_Trans_Ct', \n",
    "    'Total_Ct_Chng_Q4_Q1', \n",
    "    'Avg_Utilization_Ratio'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot barplots for categorical variables\n",
    "fig, axes = plt.subplots(2, 3, figsize = (30, 10))\n",
    "for i, col in enumerate(cat_columns):\n",
    "    r = i//3\n",
    "    c = i%3\n",
    "    df[col].value_counts('normalize').plot.bar(figure = fig, ax = axes[r][c])\n",
    "    axes[r][c].set_title(col, fontdict = {'fontsize': 'x-large'})\n",
    "    axes[r][c].tick_params(axis = 'x', rotation = 0)\n",
    "\n",
    "fig.suptitle('Categorical variables plot', fontsize = 'xx-large')\n",
    "plt.show()\n",
    "# To save the plot\n",
    "# plt.savefig('categorical_variables_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms for quantitative variables\n",
    "fig, axes = plt.subplots(5, 3, figsize = (30, 25))\n",
    "for i, col in enumerate(quant_columns):\n",
    "    r = i//3\n",
    "    c = i%3\n",
    "    df[col].hist(figure = fig, bins = 40, ax = axes[r][c])\n",
    "    axes[r][c].set_title(col, fontdict = {'fontsize': 'x-large'})\n",
    "\n",
    "fig.suptitle('Quantitative variables plot', fontsize = 'xx-large')\n",
    "plt.show()\n",
    "# To save the plot\n",
    "# plt.savefig('quantitative_variables_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distributions of 'Total_Trans_Ct' and add a smooth curve obtained using a kernel density estimate\n",
    "plt.figure(figsize = (20, 10)) \n",
    "plt.title('KDE plot of total transactions')\n",
    "sns.histplot(df['Total_Trans_Ct'], stat = 'density', kde = True)\n",
    "plt.show()\n",
    "# To save the plot\n",
    "# plt.savefig('total_transactions_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation heatmap for all variables \n",
    "plt.figure(figsize = (20, 10)) \n",
    "sns.heatmap(df.corr(), annot = False, cmap = 'Blues', linewidths = 2)\n",
    "plt.title('Correlation map')\n",
    "plt.show()\n",
    "# To save the plot\n",
    "# plt.savefig('correlation_map.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Transform target column\n",
    "df['Churn'] = df['Attrition_Flag'].apply(lambda val: 0 if val == \"Existing Customer\" else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose appropriate encoding method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Encoding categorical variables by mean target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_encode_variables = [\n",
    "    'Gender', \n",
    "    'Education_Level', \n",
    "    'Marital_Status', \n",
    "    'Income_Category', \n",
    "    'Card_Category'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# encoding categorical variables using mean target variables\n",
    "mean_encoded_cols = []\n",
    "for col in to_encode_variables:\n",
    "    col_lst = []\n",
    "    col_groups_map = df.groupby(col)['Churn'].mean().to_dict()\n",
    "    col_name = col + '_Churn'\n",
    "    df[col_name] = df[col].map(col_groups_map)\n",
    "    mean_encoded_cols.append(col_name)\n",
    "    \n",
    "print(f'Shape of new data: {df.shape}')\n",
    "print(f'Encoded columns: {mean_encoded_cols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Encoding categorical variables by one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical variables using one-hot encoding\n",
    "one_hot_encoded_cols = []\n",
    "for col in to_encode_variables:\n",
    "    tmp_df = pd.get_dummies(df[col], prefix = col, drop_first = True)\n",
    "    one_hot_encoded_cols.extend(tmp_df.columns)\n",
    "    df = pd.concat([df, tmp_df], axis = 1)\n",
    "\n",
    "print(f'Shape of new data: {df.shape}')\n",
    "print(f'Encoded columns: {one_hot_encoded_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = df['Churn']\n",
    "\n",
    "keep_mean_cols = quant_columns + mean_encoded_cols\n",
    "keep_ohe_cols = quant_columns + one_hot_encoded_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Model training and prediction with target mean encoded categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_mean = pd.DataFrame()\n",
    "X_mean[keep_mean_cols] = df[keep_mean_cols]\n",
    "X_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This cell may take up to 15-20 minutes to run\n",
    "# train test split \n",
    "X_train_mean, X_test_mean, y_train, y_test = train_test_split(X_mean, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "# grid search\n",
    "rfc_mean = RandomForestClassifier(random_state = 42)\n",
    "# Use a different solver if the default 'lbfgs' fails to converge\n",
    "# Reference: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "lrc_mean = LogisticRegression(solver = 'lbfgs', max_iter = 3000, verbose = 1)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth'   : [4, 5, 100],\n",
    "    'criterion'   : ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "cv_rfc_mean = GridSearchCV(\n",
    "    estimator  = rfc_mean, \n",
    "    param_grid = param_grid, \n",
    "    cv         = 5, \n",
    "    verbose    = 1,\n",
    "    n_jobs     = -1\n",
    ")\n",
    "cv_rfc_mean.fit(X_train_mean, y_train)\n",
    "\n",
    "lrc_mean.fit(X_train_mean, y_train)\n",
    "\n",
    "y_train_preds_rf_mean = cv_rfc_mean.best_estimator_.predict(X_train_mean)\n",
    "y_test_preds_rf_mean = cv_rfc_mean.best_estimator_.predict(X_test_mean)\n",
    "\n",
    "y_train_preds_lr_mean = lrc_mean.predict(X_train_mean)\n",
    "y_test_preds_lr_mean = lrc_mean.predict(X_test_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Model training and prediction with one-hot encoded categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ohe = pd.DataFrame()\n",
    "X_ohe[keep_ohe_cols] = df[keep_ohe_cols]\n",
    "X_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell may take up to 15-20 minutes to run\n",
    "# train test split \n",
    "X_train_ohe, X_test_ohe, y_train, y_test = train_test_split(X_ohe, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "# grid search\n",
    "rfc_ohe = RandomForestClassifier(random_state = 42)\n",
    "# Use a different solver if the default 'lbfgs' fails to converge\n",
    "# Reference: https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "lrc_ohe = LogisticRegression(solver = 'lbfgs', max_iter = 3000, verbose = 1)\n",
    "\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth'   : [4, 5, 100],\n",
    "    'criterion'   : ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "cv_rfc_ohe = GridSearchCV(\n",
    "    estimator  = rfc_ohe, \n",
    "    param_grid = param_grid, \n",
    "    cv         = 5, \n",
    "    verbose    = 1,\n",
    "    n_jobs     = -1\n",
    ")\n",
    "cv_rfc_ohe.fit(X_train_ohe, y_train)\n",
    "\n",
    "lrc_ohe.fit(X_train_ohe, y_train)\n",
    "\n",
    "y_train_preds_rf_ohe = cv_rfc_ohe.best_estimator_.predict(X_train_ohe)\n",
    "y_test_preds_rf_ohe = cv_rfc_ohe.best_estimator_.predict(X_test_ohe)\n",
    "\n",
    "y_train_preds_lr_ohe = lrc_ohe.predict(X_train_ohe)\n",
    "y_test_preds_lr_ohe = lrc_ohe.predict(X_test_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and feature selection scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores\n",
    "print('Random Forest results for mean encoding')\n",
    "print('Test results')\n",
    "print(classification_report(y_test, y_test_preds_rf_mean))\n",
    "print('Train results')\n",
    "print(classification_report(y_train, y_train_preds_rf_mean))\n",
    "\n",
    "print('Logistic Regression results for mean encoding')\n",
    "print('Test results')\n",
    "print(classification_report(y_test, y_test_preds_lr_mean))\n",
    "print('Train results')\n",
    "print(classification_report(y_train, y_train_preds_lr_mean))\n",
    "\n",
    "print('Random Forest results for one-hot encoding')\n",
    "print('Test results')\n",
    "print(classification_report(y_test, y_test_preds_rf_ohe))\n",
    "print('Train results')\n",
    "print(classification_report(y_train, y_train_preds_rf_ohe))\n",
    "\n",
    "print('Logistic Regression results for one-hot encoding')\n",
    "print('Test results')\n",
    "print(classification_report(y_test, y_test_preds_lr_ohe))\n",
    "print('Train results')\n",
    "print(classification_report(y_train, y_train_preds_lr_ohe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting best features\n",
    "X, X_train, X_test = X_mean, X_train_mean, X_test_mean\n",
    "y_train_preds_rf, y_test_preds_rf = y_train_preds_rf_mean, y_test_preds_rf_mean\n",
    "y_train_preds_lr, y_test_preds_lr = y_train_preds_lr_mean, y_test_preds_lr_mean\n",
    "cv_rfc = cv_rfc_mean\n",
    "lrc = lrc_mean\n",
    "\n",
    "print(f'Best random forest classifier parameters:\\n{cv_rfc.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "lrc_plot = plot_roc_curve(lrc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ROC plots\n",
    "plt.figure(figsize = (15, 8))\n",
    "ax = plt.gca()\n",
    "rfc_disp = plot_roc_curve(cv_rfc.best_estimator_, X_test, y_test, ax = ax, alpha = 0.8)\n",
    "lrc_plot.plot(ax = ax, alpha = 0.8)\n",
    "plt.show()\n",
    "# To save the plot\n",
    "# plt.savefig('roc_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# save best model\n",
    "joblib.dump(cv_rfc.best_estimator_, './models/rfc_model.pkl')\n",
    "joblib.dump(lrc, './models/lrc_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "rfc_model = joblib.load('./models/rfc_model.pkl')\n",
    "lr_model = joblib.load('./models/lrc_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "lrc_plot = plot_roc_curve(lr_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ROC plots\n",
    "plt.figure(figsize = (15, 8))\n",
    "ax = plt.gca()\n",
    "rfc_disp = plot_roc_curve(rfc_model, X_test, y_test, ax = ax, alpha = 0.8)\n",
    "lrc_plot.plot(ax = ax, alpha = 0.8)\n",
    "plt.show()\n",
    "# To save the plot\n",
    "# plt.savefig('roc_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(cv_rfc.best_estimator_)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_test, plot_type = \"bar\")\n",
    "# To save the plot\n",
    "# shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
    "# plt.savefig('featture_impacts.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculate feature importances for random forest classifier\n",
    "importances = cv_rfc.best_estimator_.feature_importances_\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "names = [X.columns[i] for i in indices]\n",
    "\n",
    "# Create plot\n",
    "plt.figure(figsize = (20, 5))\n",
    "\n",
    "# Create plot title\n",
    "plt.title(\"Feature Importance - random forest classifier\")\n",
    "plt.ylabel('Importance')\n",
    "\n",
    "# Add bars\n",
    "plt.bar(range(X.shape[1]), importances[indices])\n",
    "\n",
    "# Add feature names as x-axis labels\n",
    "plt.xticks(range(X.shape[1]), names, rotation = 90)\n",
    "plt.show()\n",
    "# To save the plot\n",
    "# plt.savefig('feature_importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importances for logistic regression classifier\n",
    "importances = lr_model.coef_[0]\n",
    "# Sort feature importances in descending order\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Rearrange feature names so they match the sorted feature importances\n",
    "names = [X.columns[i] for i in indices]\n",
    "\n",
    "# Create plot\n",
    "plt.figure(figsize = (20, 5))\n",
    "\n",
    "# Create plot title\n",
    "plt.title(\"Feature Importance - logistic regression classifier\")\n",
    "plt.ylabel('Importance')\n",
    "\n",
    "# Add bars\n",
    "plt.bar(range(X.shape[1]), importances[indices])\n",
    "\n",
    "# Add feature names as x-axis labels\n",
    "plt.xticks(range(X.shape[1]), names, rotation = 90)\n",
    "plt.show()\n",
    "# To save the plot\n",
    "# plt.savefig('feature_importance.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(5, 5))\n",
    "#plt.text(0.01, 0.05, str(model.summary()), {'fontsize': 12}) old approach\n",
    "plt.text(0.01, 1.25, str('Random Forest Train'), {'fontsize': 10}, fontproperties = 'monospace')\n",
    "plt.text(0.01, 0.05, str(classification_report(y_test, y_test_preds_rf)), {'fontsize': 10}, fontproperties = 'monospace') # approach improved by OP -> monospace!\n",
    "plt.text(0.01, 0.6, str('Random Forest Test'), {'fontsize': 10}, fontproperties = 'monospace')\n",
    "plt.text(0.01, 0.7, str(classification_report(y_train, y_train_preds_rf)), {'fontsize': 10}, fontproperties = 'monospace') # approach improved by OP -> monospace!\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# To save the plot\n",
    "# plt.savefig('random_forest_scores.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(5, 5))\n",
    "plt.text(0.01, 1.25, str('Logistic Regression Train'), {'fontsize': 10}, fontproperties = 'monospace')\n",
    "plt.text(0.01, 0.05, str(classification_report(y_train, y_train_preds_lr)), {'fontsize': 10}, fontproperties = 'monospace') # approach improved by OP -> monospace!\n",
    "plt.text(0.01, 0.6, str('Logistic Regression Test'), {'fontsize': 10}, fontproperties = 'monospace')\n",
    "plt.text(0.01, 0.7, str(classification_report(y_test, y_test_preds_lr)), {'fontsize': 10}, fontproperties = 'monospace') # approach improved by OP -> monospace!\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "# To save the plot\n",
    "# plt.savefig('logistic_regression_scores.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('udacity-mldevops-1st-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3acb49afeede803a4568c3abd3d286c356ad4185469fb6aeb5f6bc4e00933a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
